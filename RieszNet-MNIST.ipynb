{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, exposure\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import ifftn, fftn, fft2, ifft2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxNormalization(tensor):\n",
    "    #min max normalization\n",
    "    v_min, v_max = tensor.min(), tensor.max()\n",
    "    tensor = (tensor - v_min)/(v_max - v_min)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bc92e165d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbXUlEQVR4nO3df3DU953f8dcCYi241fZULO0qyIougToGjkuA8GP4IUisQW0oNs4V2x2fcBOfHQMNkV1fCJ3CuHPIJWdKczKkcRMMF7D54zBmCjWWDyTswyQywTWDHSoXYeQinQaNrRUyXhD69A/K9taA8GfZ5a1dPR8zO4N2v2++H775xk++7OqrgHPOCQAAA0OsFwAAGLyIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMDPMegGf19fXpzNnzigUCikQCFgvBwDgyTmn7u5ulZSUaMiQ/q91BlyEzpw5o9LSUutlAABuUmtrq0aPHt3vNgMuQqFQSJI0U/9cw5RnvBoAgK9eXdSb2pv473l/MhahjRs36qc//ana2to0btw4bdiwQbNmzbrh3JV/ghumPA0LECEAyDr/746kX+QtlYx8MGHHjh1asWKFVq1apaNHj2rWrFmqqqrS6dOnM7E7AECWykiE1q9fr+9973v6/ve/r6997WvasGGDSktLtWnTpkzsDgCQpdIeoQsXLujIkSOqrKxMer6yslKHDh26avt4PK5YLJb0AAAMDmmP0NmzZ3Xp0iUVFxcnPV9cXKz29vartq+trVU4HE48+GQcAAweGftm1c+/IeWcu+abVCtXrlRXV1fi0dramqklAQAGmLR/Om7UqFEaOnToVVc9HR0dV10dSVIwGFQwGEz3MgAAWSDtV0LDhw/XpEmTVF9fn/R8fX29ZsyYke7dAQCyWEa+T6impkYPPfSQJk+erOnTp+sXv/iFTp8+rcceeywTuwMAZKmMRGjx4sXq7OzU008/rba2No0fP1579+5VWVlZJnYHAMhSAeecs17EPxaLxRQOh1WhhdwxAQCyUK+7qAa9oq6uLhUUFPS7LT/KAQBghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJgZZr0AAF9M77xJ3jNtj8dT2tf/nL7Fe2biW9XeMyXPDfeeGXrgd94zGLi4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADU8BA35yve8/87Fd13jNfzUvt/+J9Kcwcnb7Ze+bE5EveM//uy9O8ZzBwcSUEADBDhAAAZtIeoTVr1igQCCQ9IpFIuncDAMgBGXlPaNy4cXr99dcTXw8dOjQTuwEAZLmMRGjYsGFc/QAAbigj7wk1NzerpKRE5eXluv/++3Xy5MnrbhuPxxWLxZIeAIDBIe0Rmjp1qrZu3ap9+/bp+eefV3t7u2bMmKHOzs5rbl9bW6twOJx4lJaWpntJAIABKu0Rqqqq0n333acJEybo29/+tvbs2SNJ2rJlyzW3X7lypbq6uhKP1tbWdC8JADBAZfybVUeOHKkJEyaoubn5mq8Hg0EFg8FMLwMAMABl/PuE4vG43n//fUWj0UzvCgCQZdIeoSeffFKNjY1qaWnRb37zG333u99VLBZTdXV1uncFAMhyaf/nuI8++kgPPPCAzp49q9tvv13Tpk3T4cOHVVZWlu5dAQCyXNoj9NJLL6X7twQGtIuVk71nntr4N94zY/OGe8/0pXQrUunkxYveM119/u/tfj2Ft4PjVVO8Z/IPHPPfkaS+zz5LaQ5fHPeOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMZPyH2gEWhhYUpDTXM/tO75kf/eft3jNz8895z9zKvzO+8PEM75m/2zjde+bv1/zMe6b+v/3ce+auXy/znpGkP/qLt1KawxfHlRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcBdt5KSPtn4ppbmmKc+leSXZ6emiJu+ZV//A/87bD5+q9J7Z8uXXvWcK7ur0nsGtwZUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5hiwOudN8l75sU/qUtpX0M0PKU5Xw9/+C3vmbdf/5r3zLHvpXYcDpy/zXum6O3z3jMffHyn90ze2gPeM0MC3iO4RbgSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANT3FJ9c77uPfOzX/nfhPOreamd2n3q8575l7+/13tm6Hd7vGf+yb9w3jN3/c0y7xlJGvtcq/fMkNaj3jN/+Ib3iC7+5SXvmb/941/570jSv5n7b71nhh74XUr7Gqy4EgIAmCFCAAAz3hE6ePCgFixYoJKSEgUCAe3atSvpdeec1qxZo5KSEuXn56uiokLHjx9P13oBADnEO0I9PT2aOHGi6uqu/e/069at0/r161VXV6empiZFIhHdfffd6u7uvunFAgByi/e7t1VVVaqqqrrma845bdiwQatWrdKiRYskSVu2bFFxcbG2b9+uRx999OZWCwDIKWl9T6ilpUXt7e2qrKxMPBcMBjVnzhwdOnTomjPxeFyxWCzpAQAYHNIaofb2dklScXFx0vPFxcWJ1z6vtrZW4XA48SgtLU3nkgAAA1hGPh0XCASSvnbOXfXcFStXrlRXV1fi0drq//0JAIDslNZvVo1EIpIuXxFFo9HE8x0dHVddHV0RDAYVDAbTuQwAQJZI65VQeXm5IpGI6uvrE89duHBBjY2NmjFjRjp3BQDIAd5XQufOndMHH3yQ+LqlpUXvvPOOCgsLdccdd2jFihVau3atxowZozFjxmjt2rUaMWKEHnzwwbQuHACQ/bwj9Pbbb2vu3LmJr2tqaiRJ1dXVeuGFF/TUU0/p/Pnzevzxx/Xxxx9r6tSpeu211xQKhdK3agBATgg45/zviphBsVhM4XBYFVqoYYE86+WgH4FJ47xn/uE/+N988reTt3nPHIl7j0iS9p+7y3tm51/P8575p8+/5T2Dy/77/zniPZPKjWkladrbD3nPFC38fUr7yiW97qIa9Iq6urpUUFDQ77bcOw4AYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABm0vqTVZGdhowYkdJc77qY98zhO3d6z7T0XvCeqfnJE94zkvSHb5z2nika2eE9438vcVj4ZvRD75lT6V9GTuNKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1MofNzxqU0t+/OjWleybV9/4c/8p4J7Tqc0r56U5oCkCquhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM9zAFPrj//hOSnNDUvg7zMMffst7Jn/Xb71nkLvyAkO9Zy661PY1NJDiIL4wroQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADPcwDTHfPLQdO+Zf1/8Vyntq0/DvWeOvHaX98wdOuQ9g9x10V3ynulTX0r7evV9//N1jH6X0r4GK66EAABmiBAAwIx3hA4ePKgFCxaopKREgUBAu3btSnp9yZIlCgQCSY9p06ala70AgBziHaGenh5NnDhRdXV1191m/vz5amtrSzz27t17U4sEAOQm7w8mVFVVqaqqqt9tgsGgIpFIyosCAAwOGXlPqKGhQUVFRRo7dqweeeQRdXR0XHfbeDyuWCyW9AAADA5pj1BVVZW2bdum/fv369lnn1VTU5PmzZuneDx+ze1ra2sVDocTj9LS0nQvCQAwQKX9+4QWL16c+PX48eM1efJklZWVac+ePVq0aNFV269cuVI1NTWJr2OxGCECgEEi49+sGo1GVVZWpubm5mu+HgwGFQwGM70MAMAAlPHvE+rs7FRra6ui0WimdwUAyDLeV0Lnzp3TBx98kPi6paVF77zzjgoLC1VYWKg1a9bovvvuUzQa1alTp/STn/xEo0aN0r333pvWhQMAsp93hN5++23NnTs38fWV93Oqq6u1adMmHTt2TFu3btUnn3yiaDSquXPnaseOHQqFQulbNQAgJ3hHqKKiQs65676+b9++m1oQbk5vvv9MeIj/jUgl6a3P/N/L+6OtZ7xner0nYGHIiBHeM7//q/Ep7OmI98S/Ptn/9zZez50/bPGe8b+96uDGveMAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgJuM/WRW5q/PSH3jP9J48lf6FIO1SuSP2iWcmeM/8fmGd98z/+DTsPXPmua96z0hS6OPDKc3hi+NKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1MkbIn//5PvWfG6kgGVoLr6Zvz9ZTmOmrOe8+8P9n/ZqTfOrbYe2bk/JPeMyFxI9KBiishAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMNzDNNQH/kSEp/l3kv8x80XvmOY1NaV+QPnx6uvfM3/7Z+pT2NTZvuPfMN35b7T1Tcu973jPILVwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmuIFprnH+I33qS2lXc/I7vWdWvDDJe+Yrm/3Xl9fe7T0jSf8w53bvmcLFH3nPLL/j77xnqkYc8Z7Z3VPsPSNJf3ZsvvfMqP86MqV9YXDjSggAYIYIAQDMeEWotrZWU6ZMUSgUUlFRke655x6dOHEiaRvnnNasWaOSkhLl5+eroqJCx48fT+uiAQC5wStCjY2NWrp0qQ4fPqz6+nr19vaqsrJSPT09iW3WrVun9evXq66uTk1NTYpEIrr77rvV3Z3av9EDAHKX1wcTXn311aSvN2/erKKiIh05ckSzZ8+Wc04bNmzQqlWrtGjRIknSli1bVFxcrO3bt+vRRx9N38oBAFnvpt4T6urqkiQVFhZKklpaWtTe3q7KysrENsFgUHPmzNGhQ4eu+XvE43HFYrGkBwBgcEg5Qs451dTUaObMmRo/frwkqb29XZJUXJz8sdDi4uLEa59XW1urcDiceJSWlqa6JABAlkk5QsuWLdO7776rF1988arXAoFA0tfOuaueu2LlypXq6upKPFpbW1NdEgAgy6T0zarLly/X7t27dfDgQY0ePTrxfCQSkXT5iigajSae7+jouOrq6IpgMKhgMJjKMgAAWc7rSsg5p2XLlmnnzp3av3+/ysvLk14vLy9XJBJRfX194rkLFy6osbFRM2bMSM+KAQA5w+tKaOnSpdq+fbteeeUVhUKhxPs84XBY+fn5CgQCWrFihdauXasxY8ZozJgxWrt2rUaMGKEHH3wwI38AAED28orQpk2bJEkVFRVJz2/evFlLliyRJD311FM6f/68Hn/8cX388ceaOnWqXnvtNYVCobQsGACQOwLOuRRueZk5sVhM4XBYFVqoYYE86+VknbN/Pt175tDqn2VgJenz5me3ec80xyMp7evh8KmU5m6FH52Z5T3z6qE/SWlfY354OKU5QJJ63UU16BV1dXWpoKCg3225dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMpPSTVTFwFTd0eM/8xaP+d96WpP8UeSulOV+zb7vgPTPztlPpX8h1HI37/13ugcY/954Z+/AR75kx4m7YGNi4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHAD0xxz6X/9b++Z5j/9ckr7umv5cu+Z9/7VX6e0r1vlzr2Pe8/8s42fes+MPep/M1IgF3ElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYCTjnnPUi/rFYLKZwOKwKLdSwQJ71cgAAnnrdRTXoFXV1damgoKDfbbkSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa8IlRbW6spU6YoFAqpqKhI99xzj06cOJG0zZIlSxQIBJIe06ZNS+uiAQC5wStCjY2NWrp0qQ4fPqz6+nr19vaqsrJSPT09SdvNnz9fbW1ticfevXvTumgAQG4Y5rPxq6++mvT15s2bVVRUpCNHjmj27NmJ54PBoCKRSHpWCADIWTf1nlBXV5ckqbCwMOn5hoYGFRUVaezYsXrkkUfU0dFx3d8jHo8rFoslPQAAg0PKEXLOqaamRjNnztT48eMTz1dVVWnbtm3av3+/nn32WTU1NWnevHmKx+PX/H1qa2sVDocTj9LS0lSXBADIMgHnnEtlcOnSpdqzZ4/efPNNjR49+rrbtbW1qaysTC+99JIWLVp01evxeDwpULFYTKWlparQQg0L5KWyNACAoV53UQ16RV1dXSooKOh3W6/3hK5Yvny5du/erYMHD/YbIEmKRqMqKytTc3PzNV8PBoMKBoOpLAMAkOW8IuSc0/Lly/Xyyy+roaFB5eXlN5zp7OxUa2urotFoyosEAOQmr/eEli5dql//+tfavn27QqGQ2tvb1d7ervPnz0uSzp07pyeffFJvvfWWTp06pYaGBi1YsECjRo3Svffem5E/AAAge3ldCW3atEmSVFFRkfT85s2btWTJEg0dOlTHjh3T1q1b9cknnygajWru3LnasWOHQqFQ2hYNAMgN3v8c15/8/Hzt27fvphYEABg8uHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMDMMOsFfJ5zTpLUq4uSM14MAMBbry5K+v//Pe/PgItQd3e3JOlN7TVeCQDgZnR3dyscDve7TcB9kVTdQn19fTpz5oxCoZACgUDSa7FYTKWlpWptbVVBQYHRCu1xHC7jOFzGcbiM43DZQDgOzjl1d3erpKREQ4b0/67PgLsSGjJkiEaPHt3vNgUFBYP6JLuC43AZx+EyjsNlHIfLrI/Dja6AruCDCQAAM0QIAGAmqyIUDAa1evVqBYNB66WY4jhcxnG4jONwGcfhsmw7DgPugwkAgMEjq66EAAC5hQgBAMwQIQCAGSIEADCTVRHauHGjysvLddttt2nSpEl64403rJd0S61Zs0aBQCDpEYlErJeVcQcPHtSCBQtUUlKiQCCgXbt2Jb3unNOaNWtUUlKi/Px8VVRU6Pjx4zaLzaAbHYclS5ZcdX5MmzbNZrEZUltbqylTpigUCqmoqEj33HOPTpw4kbTNYDgfvshxyJbzIWsitGPHDq1YsUKrVq3S0aNHNWvWLFVVVen06dPWS7ulxo0bp7a2tsTj2LFj1kvKuJ6eHk2cOFF1dXXXfH3dunVav3696urq1NTUpEgkorvvvjtxH8JccaPjIEnz589POj/27s2tezA2NjZq6dKlOnz4sOrr69Xb26vKykr19PQkthkM58MXOQ5SlpwPLkt885vfdI899ljSc3feeaf78Y9/bLSiW2/16tVu4sSJ1sswJcm9/PLLia/7+vpcJBJxzzzzTOK5zz77zIXDYffzn//cYIW3xuePg3POVVdXu4ULF5qsx0pHR4eT5BobG51zg/d8+PxxcC57zoesuBK6cOGCjhw5osrKyqTnKysrdejQIaNV2WhublZJSYnKy8t1//336+TJk9ZLMtXS0qL29vakcyMYDGrOnDmD7tyQpIaGBhUVFWns2LF65JFH1NHRYb2kjOrq6pIkFRYWShq858Pnj8MV2XA+ZEWEzp49q0uXLqm4uDjp+eLiYrW3txut6tabOnWqtm7dqn379un5559Xe3u7ZsyYoc7OTuulmbnyv/9gPzckqaqqStu2bdP+/fv17LPPqqmpSfPmzVM8HrdeWkY451RTU6OZM2dq/Pjxkgbn+XCt4yBlz/kw4O6i3Z/P/2gH59xVz+WyqqqqxK8nTJig6dOn6ytf+Yq2bNmimpoaw5XZG+znhiQtXrw48evx48dr8uTJKisr0549e7Ro0SLDlWXGsmXL9O677+rNN9+86rXBdD5c7zhky/mQFVdCo0aN0tChQ6/6m0xHR8dVf+MZTEaOHKkJEyaoubnZeilmrnw6kHPjatFoVGVlZTl5fixfvly7d+/WgQMHkn70y2A7H653HK5loJ4PWRGh4cOHa9KkSaqvr096vr6+XjNmzDBalb14PK73339f0WjUeilmysvLFYlEks6NCxcuqLGxcVCfG5LU2dmp1tbWnDo/nHNatmyZdu7cqf3796u8vDzp9cFyPtzoOFzLgD0fDD8U4eWll15yeXl57pe//KV777333IoVK9zIkSPdqVOnrJd2yzzxxBOuoaHBnTx50h0+fNh95zvfcaFQKOePQXd3tzt69Kg7evSok+TWr1/vjh496j788EPnnHPPPPOMC4fDbufOne7YsWPugQcecNFo1MViMeOVp1d/x6G7u9s98cQT7tChQ66lpcUdOHDATZ8+3X3pS1/KqePwgx/8wIXDYdfQ0ODa2toSj08//TSxzWA4H250HLLpfMiaCDnn3HPPPefKysrc8OHD3Te+8Y2kjyMOBosXL3bRaNTl5eW5kpISt2jRInf8+HHrZWXcgQMHnKSrHtXV1c65yx/LXb16tYtEIi4YDLrZs2e7Y8eO2S46A/o7Dp9++qmrrKx0t99+u8vLy3N33HGHq66udqdPn7Zedlpd688vyW3evDmxzWA4H250HLLpfOBHOQAAzGTFe0IAgNxEhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJj5v4ccDVKOJlNOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"mnist_train.csv\", header=None)\n",
    "train_data = train_data.to_numpy()\n",
    "img = train_data[1,1:]\n",
    "img = img.reshape(28,28)\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(60000,)\n",
      "torch.Size([50000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_x = train_data[:,1:]\n",
    "train_x = train_x.reshape([train_x.shape[0],1,28,28])\n",
    "train_y = train_data[:,0]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "train_x  = torch.from_numpy(train_x).float()\n",
    "#train_x = train_x.reshape([train_x.shape[0], train_x.shape[1],1,1])\n",
    "train_y  = torch.from_numpy(train_y).long()\n",
    "#train_y = train_y.reshape(train_y.shape[0])\n",
    "\n",
    "t1 = train_x[10000:]\n",
    "t2 = train_y[10000:]\n",
    "print(t1.shape)\n",
    "\n",
    "ted1 = train_x[:10000]\n",
    "ted2 = train_y[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riesz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeRange(size_n):\n",
    "    output = np.zeros(size_n)\n",
    "    center = int(size_n/2)\n",
    "    for i in range(size_n):\n",
    "        output[i] = (i-center)/(size_n - (size_n%2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RieszDerivatives(img, order):\n",
    "    #get image size\n",
    "    size_x, size_y = img.shape\n",
    "    Riesz_kernel = np.zeros(img.shape, dtype=complex)\n",
    "    #get riesz kernel in fourier domain\n",
    "    gx = MakeRange(size_x)\n",
    "    gy = MakeRange(size_y)\n",
    "    for i in range(size_x):\n",
    "        for j in range(size_y):\n",
    "            den = gx[i]*gx[i]+gy[j]*gy[j]\n",
    "            if den > 1e-08:\n",
    "                if(order[0] == 0 and order[1] == 1):\n",
    "                    den = np.sqrt(den)\n",
    "                    Riesz_kernel[i,j] = complex(0,-gy[j]/den)\n",
    "                if(order[0] == 1 and order[1] == 0):\n",
    "                    den = np.sqrt(den)\n",
    "                    Riesz_kernel[i,j] = complex(0,-gx[i]/den)\n",
    "                if(order[0] == 2 and order[1] == 0):\n",
    "                    Riesz_kernel[i,j] = complex(gx[i]*gx[i]/den,0)\n",
    "                if(order[0] == 1 and order[1] == 1):\n",
    "                    Riesz_kernel[i,j] = complex(gx[i]*gy[j]/den,0)\n",
    "                if(order[0] == 0 and order[1] == 2):\n",
    "                    Riesz_kernel[i,j] = complex(gy[j]*gy[j]/den,0)\n",
    "                    \n",
    "    #fourier transform of the image\n",
    "    fft_img = fft2(img)\n",
    "    fft_img = np.fft.fftshift(fft_img)\n",
    "    result = np.multiply(fft_img, Riesz_kernel)\n",
    "    result = np.fft.ifftshift(result)\n",
    "    result = ifft2(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me:\n",
    "\n",
    "### Useful links:\n",
    "\n",
    "We follow tutorial on pytorch:\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "\n",
    "How to make parameters to non-trainable?\n",
    "https://discuss.pytorch.org/t/are-torch-nn-functional-layers-learnable/13687/2\n",
    "\n",
    "\n",
    "How to implement Gaussian filter?\n",
    "https://discuss.pytorch.org/t/gaussian-kernel-layer/37619\n",
    "\n",
    "How to get high-order derivative of Gaussian filter?\n",
    "https://dsp.stackexchange.com/questions/78280/are-scipy-second-order-gaussian-derivatives-correct\n",
    "\n",
    "How to concatenate layers?\n",
    "https://discuss.pytorch.org/t/concatenate-layer-output-with-additional-input-data/20462\n",
    "\n",
    "\n",
    "### Goal:\n",
    "\n",
    "implement Gaussian derivative neural network for multiscale analysis from:\n",
    "Lindeberg, T. Scale-Covariant and Scale-Invariant Gaussian Derivative Networks. J Math Imaging Vis (2021). \n",
    "https://doi.org/10.1007/s10851-021-01057-9\n",
    "or \n",
    "https://arxiv.org/abs/2011.14759\n",
    "\n",
    "Aim: adapt it for multiscale data segmentation of crack in CT images of concrete.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RieszKernelVar(s_x, s_y, order):\n",
    "    #get riesz kernel in fourier domain\n",
    "    size_x = s_x\n",
    "    size_y = s_y\n",
    "    Riesz_kernel = np.zeros([size_x, size_y], dtype=complex)\n",
    "    gx = MakeRange(size_x)\n",
    "    gy = MakeRange(size_y)\n",
    "    for i in range(size_x):\n",
    "        for j in range(size_y):\n",
    "            den = gx[i]*gx[i]+gy[j]*gy[j]\n",
    "            if den > 1e-08:\n",
    "                if(order[0] == 0 and order[1] == 1):\n",
    "                    den = np.sqrt(den)\n",
    "                    Riesz_kernel[i,j] = complex(0,-gy[j]/den)\n",
    "                if(order[0] == 1 and order[1] == 0):\n",
    "                    den = np.sqrt(den)\n",
    "                    Riesz_kernel[i,j] = complex(0,-gx[i]/den)\n",
    "                if(order[0] == 2 and order[1] == 0):\n",
    "                    Riesz_kernel[i,j] = complex(gx[i]*gx[i]/den,0)\n",
    "                if(order[0] == 1 and order[1] == 1):\n",
    "                    Riesz_kernel[i,j] = complex(gx[i]*gy[j]/den,0)\n",
    "                if(order[0] == 0 and order[1] == 2):\n",
    "                    Riesz_kernel[i,j] = complex(gy[j]*gy[j]/den,0)\n",
    "    Riesz_kernel2 = torch.from_numpy(Riesz_kernel)\n",
    "    Riesz_kernel2= Riesz_kernel2.reshape([1,1,size_x,size_y])\n",
    "    return Riesz_kernel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RieszLayer(nn.Module):\n",
    "    def __init__(self, order):\n",
    "        super(RieszLayer, self).__init__()\n",
    "\n",
    "        self.order = order\n",
    "        self.size_x = 64\n",
    "        self.size_y = 64\n",
    "        self.Riesz_fft = RieszKernelVar(self.size_x,self.size_y, self.order)\n",
    " \n",
    "    def forward(self, x):\n",
    "        #Riesz_fft = RieszKernel(x, self.order)\n",
    "        if x.size()[2] != self.size_x or x.size()[3] != self.size_y:\n",
    "            self.size_x = x.size()[2]\n",
    "            self.size_y = x.size()[3]\n",
    "            self.Riesz_fft = RieszKernelVar(self.size_x, self.size_y, self.order)\n",
    "            \n",
    "\n",
    "        x = x*self.Riesz_fft\n",
    "\n",
    "        return x\n",
    "    \n",
    "class RieszNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RieszNet, self).__init__()\n",
    "        self.order1 = [1, 0]\n",
    "        self.order2 = [0, 1]\n",
    "        self.Rx = RieszLayer(self.order1)\n",
    "        self.Ry = RieszLayer(self.order2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.fft.fft2(x)\n",
    "        x = torch.fft.fftshift(x, dim = [2,3])\n",
    "        x1 = self.Rx(x)\n",
    "        x2 = self.Ry(x)\n",
    "        x3 = -self.Rx(x1)\n",
    "        x4 = -self.Rx(x2)\n",
    "        x5 = -self.Ry(x2)\n",
    " \n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "        x = torch.fft.ifftshift(x, dim = [2,3])\n",
    "        x = torch.real(torch.fft.ifft2(x)).double()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "#12-14-16-20-64 c\n",
    "class RieszNetDeep(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RieszNetDeep, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(5,12,kernel_size = (1,1))\n",
    "        self.conv2 = nn.Conv2d(60,16,kernel_size = (1,1))\n",
    "        self.conv3 = nn.Conv2d(80,24,kernel_size = (1,1))\n",
    "        self.conv4 = nn.Conv2d(120,32,kernel_size = (1,1))\n",
    "        self.conv5 = nn.Conv2d(160,80,kernel_size = (1,1))\n",
    "        self.conv6 = nn.Conv2d(80,10,kernel_size = (1,1))\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(12, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(16, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(24, affine=True)\n",
    "        self.bn4 = nn.BatchNorm2d(32, affine=True)\n",
    "        self.bn5 = nn.BatchNorm2d(80, affine=True)\n",
    "        \n",
    "        self.GL1 = RieszNet()\n",
    "\n",
    "\n",
    "    def forward(self, y):\n",
    "        \n",
    "        #1st  layer\n",
    "        x = self.GL1(y)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        #2nd layer\n",
    "        x = self.GL1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        #3rd layer\n",
    "        x = self.GL1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        #4th layer\n",
    "        x = self.GL1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        #5th layer\n",
    "        x = self.GL1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        #final layer\n",
    "        x = self.conv6(x)\n",
    "        x = F.softmax(x)\n",
    "        x = x[:,:,int(x.shape[2]/2),int(x.shape[2]/2)]\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20882"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LN = RieszNetDeep()\n",
    "\n",
    "model = LN.double()\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barisin\\AppData\\Local\\Temp\\ipykernel_8540\\2195971149.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\n",
      "1\n",
      "Train loss:\n",
      "tensor(1.5657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "val:\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20 # or whatever\n",
    "batch_size = 50 # or whatever\n",
    "train_num = 50000\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = sched.StepLR(optimizer, step_size = 7, gamma = 0.5)\n",
    "criterion_val = loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#train data\n",
    "input = t1.double()\n",
    "target = t2\n",
    "#validation\n",
    "input_v = ted1.double()\n",
    "target_v = ted2\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    permutation = torch.randperm(train_num)\n",
    "    if(epoch % 2 == 1):\n",
    "        print(\"Epoch:\")\n",
    "        print(epoch)\n",
    "        print(\"Train loss:\")\n",
    "        print(t_loss/train_num*batch_size)\n",
    "        print(\"val:\")\n",
    "        val_loss=0\n",
    "        model.eval()\n",
    "        for i in range(200):\n",
    "            v1 = model(input_v[(i*50):((i+1)*50)])\n",
    "            v2  = target_v[(i*50):((i+1)*50)]\n",
    " \n",
    "            val_loss = val_loss + criterion_val(v1,v2)\n",
    "        print(\"Validation loss:\")\n",
    "        print(val_loss/10000*50)\n",
    "        print(\"--------\")\n",
    "    t_loss = 0\n",
    "    gc.collect()\n",
    "    model.train()\n",
    "\n",
    "    for i in range(0,train_num, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        indices = permutation[i:(i+batch_size)]\n",
    "        batch_x = input[indices]\n",
    "        batch_y = target[indices]\n",
    "        outputs = model.forward(batch_x)\n",
    "        loss = criterion_val(outputs,batch_y)\n",
    "\n",
    "        if(epoch % 2 == 0):\n",
    "            t_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        gc.collect()\n",
    "\n",
    "    scheduler.step()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"riesznet-mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"mnist_test.csv\")\n",
    "test_data = test_data.to_numpy()\n",
    "\n",
    "test_x = test_data[:,1:]\n",
    "test_x = test_x.reshape([test_x.shape[0],1,28,28])\n",
    "test_y = test_data[:,0]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "test_x  = torch.from_numpy(test_x).float()\n",
    "#test_x = test_x.reshape([test_x.shape[0], test_x.shape[1],1,1])\n",
    "test_y  = torch.from_numpy(test_y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y1,y2):\n",
    "    train_acc = torch.sum(y1 == y2)\n",
    "    final_train_acc = train_acc/y2.shape[0]\n",
    "    return final_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RieszNetDeep(\n",
       "  (conv1): Conv2d(5, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2): Conv2d(60, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3): Conv2d(80, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv4): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv5): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv6): Conv2d(80, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn5): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (GL1): RieszNet(\n",
       "    (Rx): RieszLayer()\n",
       "    (Ry): RieszLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"riesznet-mnist.pth\"))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
